{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgb/27p56okX6aHLNhSFRj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivek-bombatkar/MyLearningNotes/blob/master/ML/TF4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlZiZ3U1kWmn"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF57ti8knEUt"
      },
      "source": [
        "# dataset = tf.data.Dataset.range(10)\r\n",
        "# dataset = dataset.window(5, shift=1, drop_remainder=True)\r\n",
        "# dataset = dataset.flat_map(lambda window: window.batch(5))\r\n",
        "# dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\r\n",
        "# dataset = dataset.shuffle(buffer_size=10)\r\n",
        "# dataset = dataset.batch(2).prefetch(1)\r\n",
        "# for x,y in dataset:\r\n",
        "#   print(\"x = \", x.numpy())\r\n",
        "#   print(\"y = \", y.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAFRrn_pkaPs"
      },
      "source": [
        "ds = tf.data.Dataset.range(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9P3nHlFkhdX"
      },
      "source": [
        "ds = ds.window(size=20, shift=1,stride =1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "coG9MtYJkwvd",
        "outputId": "6bc7097c-82c4-4a97-981b-a074241256e3"
      },
      "source": [
        "ds = ds.flat_map(lambda window:)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-6069c8d91078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1835\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m     \"\"\"\n\u001b[0;32m-> 1837\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m   def interleave(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   4283\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4284\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 4285\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   4286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4287\u001b[0m       raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3052\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3517\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3453\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3454\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: <lambda>() takes 1 positional argument but 2 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sDMnhCOk7XI"
      },
      "source": [
        "ds = ds.map(lambda window: (window[:-1], window[-1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56IwC1HylHMo"
      },
      "source": [
        "ds = ds.shuffle(buffer_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHXwyxkml_GD"
      },
      "source": [
        "ds = ds.batch(2).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuRRezWWmGCc",
        "outputId": "f05a4d69-eec6-4e2f-f8f9-107088c19061"
      },
      "source": [
        "for i,j in ds:\r\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[4 5 6 7]\n",
            " [5 6 7 8]], shape=(2, 4), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[3 4 5 6]\n",
            " [1 2 3 4]], shape=(2, 4), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[2 3 4 5]\n",
            " [0 1 2 3]], shape=(2, 4), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3_Qb7JWpv9e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkOtkY1Zpvz-"
      },
      "source": [
        "# l0 = tf.keras.layers.Dense(1, input_shape=[20])\r\n",
        "# model = tf.keras.models.Sequential([l0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9A95HQAq4sO"
      },
      "source": [
        "\r\n",
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\r\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(series)\r\n",
        "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\r\n",
        "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\r\n",
        "  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\r\n",
        "  dataset = dataset.batch(batch_size).prefetch(1)\r\n",
        "  return dataset"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCE1M4D8q5FS"
      },
      "source": [
        "window_size = 20\r\n",
        "batch_size = 32\r\n",
        "shuffle_buffer_size = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "04e_2whZq6dP",
        "outputId": "0bf2040a-6bb9-43cf-cc7a-ae89b5e1e3f2"
      },
      "source": [
        "ds = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-81de4027e21a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindowed_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle_buffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTaOG9S9nqxm"
      },
      "source": [
        "l0 = tf.keras.layers.Dense(1,input_shape=[20])\r\n",
        "ts_model = tf.keras.models.Sequential([l0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3LspiHFp266"
      },
      "source": [
        "ts_model.compile(\r\n",
        "    optimizer=tf.keras.optimizers.SGD(lr=1e-6,momentum=0.9),\r\n",
        "    loss='mse',\r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "_V0W-3qcqPRz",
        "outputId": "4d9a9dfe-6686-482c-87c7-45fcea5a209c"
      },
      "source": [
        "ts_model.fit(ds,epochs=100,verbose=0)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-753dcd2160ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:201 assert_input_compatibility\n        raise TypeError('Inputs to a layer should be tensors. Got: %s' % (x,))\n\n    TypeError: Inputs to a layer should be tensors. Got: <_VariantDataset shapes: (None, None), types: tf.int64>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNqq3RJuHnlG"
      },
      "source": [
        "# RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNNL-dIupEJs"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv4sn8YBHtQ9"
      },
      "source": [
        "tf.keras.backend.clear_session()\r\n",
        "tf.random.set_seed(51)\r\n",
        "np.random.seed(51)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzPIsiO-IQWz"
      },
      "source": [
        "def trend(time, slope=0):\r\n",
        "  return slope * time"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4GOqY6jJZ4l"
      },
      "source": [
        "def seasonal_pattern(season_time):\r\n",
        "  return np.where(\r\n",
        "      season_time < 0.4 ,\r\n",
        "      np.cos(season_time * 2 * np.pi),\r\n",
        "      1 / np.exp(3 * season_time)\r\n",
        "  )"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdPIv7mwIgTX"
      },
      "source": [
        "def seasonality(time,period,amplitude=1,phase=0):\r\n",
        "  season_time = ((time + phase) % period )/ period\r\n",
        "  return amplitude * seasonal_pattern(season_time)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhpF0bEnKIeS"
      },
      "source": [
        "def noise(time, noise_level=1 ,seed=None):\r\n",
        "  rnd = np.random.RandomState(seed)\r\n",
        "  return rnd.random(len(time)) * noise_level"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGAYLpqqIM2r"
      },
      "source": [
        "time = np.arange(4 * 365 + 1, dtype=\"float32\")\r\n",
        "baseline = 10\r\n",
        "series = trend(time, 0.1)  \r\n",
        "baseline = 10\r\n",
        "amplitude = 40\r\n",
        "slope = 0.05\r\n",
        "noise_level = 5\r\n",
        "\r\n",
        "# Create the series\r\n",
        "series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\r\n",
        "# Update with noise\r\n",
        "series += noise(time, noise_level, seed=42)\r\n",
        "\r\n",
        "split_time = 1000\r\n",
        "time_train = time[:split_time]\r\n",
        "x_train = series[:split_time]\r\n",
        "time_valid = time[split_time:]\r\n",
        "x_valid = series[split_time:]\r\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU8alvjaH9Ph"
      },
      "source": [
        "train_set = windowed_dataset(\r\n",
        "    x_train,\r\n",
        "    window_size,\r\n",
        "    batch_size=128,\r\n",
        "    shuffle_buffer = shuffle_buffer_size\r\n",
        ")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WANIlLRhKu4w",
        "outputId": "21ebb48f-2960-4c67-e25e-6557f247feb3"
      },
      "source": [
        "train_set"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None, None), (None,)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqJAyql_OuZb"
      },
      "source": [
        "1. model build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HnJ4xOIKwrL"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "rnn_model = tf.keras.models.Sequential([\r\n",
        "                                        layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[None]),\r\n",
        "                                        layers.SimpleRNN(40, return_sequences=True),\r\n",
        "                                        layers.SimpleRNN(40),\r\n",
        "                                        layers.Dense(1),\r\n",
        "                                        layers.Lambda(lambda x: x * 100.0)\r\n",
        "])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JalVdZ1WOwtz"
      },
      "source": [
        "2. learning rate scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vr26g2VL6-O"
      },
      "source": [
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\r\n",
        "    lambda epoch: 1e-8 * 10 **(epoch / 20)\r\n",
        ") "
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-il_RjgOzBU"
      },
      "source": [
        "3. optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe9lF9SGN1au"
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(lr=5e-5, momentum=0.9)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zXzMtkiPLAH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwydtptDO2Sn"
      },
      "source": [
        "4. compile "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxh51MPaOhrn"
      },
      "source": [
        "rnn_model.compile(loss=tf.keras.losses.Huber(),\r\n",
        "                  optimizer=optimizer,\r\n",
        "                  metrics=['mae'])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpOQc4epPlaT",
        "outputId": "c2d7a874-cd05-44d5-8fc2-17089377c2c9"
      },
      "source": [
        "history = rnn_model.fit(train_set,\r\n",
        "                        epochs=500,\r\n",
        "                        callbacks=[lr_schedule])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 2s 20ms/step - loss: 47.9658 - mae: 48.4658\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 47.3385 - mae: 47.8385\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 47.5410 - mae: 48.0410\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 45.5348 - mae: 46.0348\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 44.8185 - mae: 45.3185\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 42.5724 - mae: 43.0724\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 39.7488 - mae: 40.2488\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 38.7202 - mae: 39.2202\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 35.6417 - mae: 36.1417\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 33.9913 - mae: 34.4913\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 30.5115 - mae: 31.0115\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27.0449 - mae: 27.5449\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 24.9546 - mae: 25.4538\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 20.1913 - mae: 20.6792\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 18.8236 - mae: 19.3108\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 17.3269 - mae: 17.8238\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 17.6157 - mae: 18.1037\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 16.1691 - mae: 16.6512\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 15.8469 - mae: 16.3316\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.4577 - mae: 16.9355\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 16.6487 - mae: 17.1291\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 17.1510 - mae: 17.6291\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.1765 - mae: 16.6564\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 16.6719 - mae: 17.1490\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.5516 - mae: 16.0325\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.5056 - mae: 15.9856\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 15.1951 - mae: 15.6741\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 16.4850 - mae: 16.9625\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 14.9756 - mae: 15.4571\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14.5443 - mae: 15.0235\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 14.6140 - mae: 15.0919\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 13.1593 - mae: 13.6342\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.2501 - mae: 14.7277\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 12.6143 - mae: 13.0891\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 12.5160 - mae: 12.9891\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 11.5643 - mae: 12.0329\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11.1151 - mae: 11.5869\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 10.7263 - mae: 11.1924\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 10.2701 - mae: 10.7361\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 9.0853 - mae: 9.5540\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.7471 - mae: 9.2124\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.4154 - mae: 8.8726\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.3215 - mae: 8.7836\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.0311 - mae: 8.4855\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8.0210 - mae: 8.4730\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 6.8708 - mae: 7.3410\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 6.7093 - mae: 7.1849\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5.6937 - mae: 6.1466\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 5.4269 - mae: 5.8748\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 5.0132 - mae: 5.4701\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.2507 - mae: 4.7052\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4.5684 - mae: 5.0371\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4.0226 - mae: 4.4725\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 6.3285 - mae: 6.8132\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 12.4746 - mae: 12.9692\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9.9520 - mae: 10.4475\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.6968 - mae: 9.1866\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7.4798 - mae: 7.9629\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 6.2898 - mae: 6.7801\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.3468 - mae: 7.8368\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8.1851 - mae: 8.6691\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5.7963 - mae: 6.2710\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.9512 - mae: 9.4406\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 13.7078 - mae: 14.2059\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 10.3196 - mae: 10.8161\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.8277 - mae: 8.3144\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 6.7010 - mae: 7.1892\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 18.0179 - mae: 18.5110\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15.2721 - mae: 15.7661\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 12.1463 - mae: 12.6362\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.2704 - mae: 8.7627\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8.4419 - mae: 8.9260\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 16.3942 - mae: 16.8908\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 16.2211 - mae: 16.7129\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 14.5183 - mae: 15.0061\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10.4116 - mae: 10.9068\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11.8500 - mae: 12.3432\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 19.4013 - mae: 19.8995\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 17.7397 - mae: 18.2362\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 15.3396 - mae: 15.8358\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16.2386 - mae: 16.7319\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 20.7095 - mae: 21.2059\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 26.4313 - mae: 26.9296\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 22.6962 - mae: 23.1953\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 26.9379 - mae: 27.4375\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17.3311 - mae: 17.8286\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 25.3140 - mae: 25.8051\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.0772 - mae: 21.5727\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21.2490 - mae: 21.7459\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20.7035 - mae: 21.1954\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 20.6914 - mae: 21.1878\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 18.5622 - mae: 19.0571\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 50.9428 - mae: 51.4427\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 48.6604 - mae: 49.1595\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 59.8190 - mae: 60.3188\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 68.7460 - mae: 69.2458\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 47.6724 - mae: 48.1654\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 108.4272 - mae: 108.9272\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 99.4753 - mae: 99.9751\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 33.7319 - mae: 34.2298\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 122.7510 - mae: 123.2508\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 190.5875 - mae: 191.0874\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 124.2808 - mae: 124.7808\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 123.0393 - mae: 123.5393\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 130.2671 - mae: 130.7668\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 168.1466 - mae: 168.6464\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 331.5866 - mae: 332.0861\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 525.6859 - mae: 526.1859\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 640.9878 - mae: 641.4878\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1049.7838 - mae: 1050.2838\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1381.0070 - mae: 1381.5070\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1421.5390 - mae: 1422.0390\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 319.8740 - mae: 320.3737\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 732.7433 - mae: 733.2432\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1956.2215 - mae: 1956.7215\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1996.1754 - mae: 1996.6754\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2780.0598 - mae: 2780.5598\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2850.0149 - mae: 2850.5149\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 690.2677 - mae: 690.7677\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1069.1768 - mae: 1069.6768\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2246.3031 - mae: 2246.8031\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3938.4223 - mae: 3938.9223\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2207.9388 - mae: 2208.4388\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 6337.8772 - mae: 6338.3772\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 5643.3300 - mae: 5643.8300\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 6298.8704 - mae: 6299.3704\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4446.0714 - mae: 4446.5714\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 5674.7568 - mae: 5675.2568\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 10532.8308 - mae: 10533.3308\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9668.1529 - mae: 9668.6529\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 13704.8341 - mae: 13705.3341\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 12027.5788 - mae: 12028.0788\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 26164.2693 - mae: 26164.7693\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 16937.0622 - mae: 16937.5622\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17785.1123 - mae: 17785.6123\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10675.7924 - mae: 10676.2924\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 23097.2695 - mae: 23097.7695\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 24668.7694 - mae: 24669.2694\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 26429.7459 - mae: 26430.2459\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21077.4173 - mae: 21077.9173\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 63156.9371 - mae: 63157.4371\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 26395.9043 - mae: 26396.4043\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 61473.1350 - mae: 61473.6359\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 49651.9327 - mae: 49652.4327\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 121175.8924 - mae: 121176.3924\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 50682.2982 - mae: 50682.7982\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 92802.5595 - mae: 92803.0595\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 144793.6727 - mae: 144794.1727\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 154905.5911 - mae: 154906.0911\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 83118.4844 - mae: 83118.9844\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 82900.1063 - mae: 82900.6046\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 62909.9852 - mae: 62910.4852\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 87332.3628 - mae: 87332.8611\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 92679.7387 - mae: 92680.2370\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 101874.4475 - mae: 101874.9475\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 104828.0955 - mae: 104828.5972\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 321083.8993 - mae: 321084.3993\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 702727.8021 - mae: 702728.3021\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 139475.0634 - mae: 139475.5634\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 310726.9149 - mae: 310727.4149\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 353938.8767 - mae: 353939.3837\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 453754.6840 - mae: 453755.1840\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 259329.8281 - mae: 259330.3351\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 502987.2014 - mae: 502987.7083\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 705843.7917 - mae: 705844.2917\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 669293.1458 - mae: 669293.6528\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 196964.1024 - mae: 196964.6024\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 501754.5095 - mae: 501754.9957\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 872024.0417 - mae: 872024.5694\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 375961.5278 - mae: 375962.0278\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 336335.4583 - mae: 336335.9583\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 407186.0660 - mae: 407186.5660\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 868105.8229 - mae: 868106.3229\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1069915.8542 - mae: 1069916.4028\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2403863.7361 - mae: 2403864.2639\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 3395370.6667 - mae: 3395371.1667\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1122419.3958 - mae: 1122419.8958\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1469770.7917 - mae: 1469771.2222\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3598273.8889 - mae: 3598274.5833\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 5360572.2500 - mae: 5360572.2500\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5198099.7222 - mae: 5198100.2500\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3973455.3056 - mae: 3973455.8333\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2317503.6528 - mae: 2317504.1528\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5399146.9444 - mae: 5399147.4444\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5548937.9722 - mae: 5548938.8333\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7137183.9444 - mae: 7137184.1667\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9167397.1111 - mae: 9167397.2222\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7856615.2500 - mae: 7856615.3611\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11014203.7778 - mae: 11014205.1111\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11225038.0000 - mae: 11225039.0000\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 2864780.9722 - mae: 2864781.4722\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4320899.8889 - mae: 4320900.7500\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 8794883.0000 - mae: 8794883.2778\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15559875.5556 - mae: 15559876.0000\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 39425528.4444 - mae: 39425528.4444\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 22184920.2222 - mae: 22184921.4444\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 30858527.1111 - mae: 30858527.1111\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 42453514.4444 - mae: 42453514.4444\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 16975733.5278 - mae: 16975735.8889\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 59531398.2222 - mae: 59531398.2222\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 118652498.6667 - mae: 118652498.6667\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 81056192.5556 - mae: 81056192.6667\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 128777024.8889 - mae: 128777024.8889\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 135877864.8889 - mae: 135877864.8889\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 127594475.5556 - mae: 127594475.5556\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 60615293.3333 - mae: 60615293.7778\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 34571750.8889 - mae: 34571750.8889\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 91942344.8889 - mae: 91942344.8889\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 88262792.8889 - mae: 88262792.8889\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 109685365.3333 - mae: 109685365.3333\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 146075957.3333 - mae: 146075957.3333\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 123992038.6667 - mae: 123992038.8889\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 174327301.3333 - mae: 174327301.3333\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 173580506.6667 - mae: 173580506.6667\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 47611946.6667 - mae: 47611946.6667\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 264771121.7778 - mae: 264771121.7778\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 126594995.1111 - mae: 126594995.1111\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 265990312.8889 - mae: 265990312.8889\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 333543854.2222 - mae: 333543854.2222\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 80893136.0000 - mae: 80893136.0000\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 280819288.8889 - mae: 280819288.8889\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 247764074.6667 - mae: 247764074.6667\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 278045728.0000 - mae: 278045728.0000\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 335587808.0000 - mae: 335587808.0000\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 224659131.1111 - mae: 224659131.1111\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 571996625.7778 - mae: 571996625.7778\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1167179405.3333 - mae: 1167179405.3333\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 352278471.1111 - mae: 352278471.1111\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 451694232.8889 - mae: 451694232.8889\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 670304736.0000 - mae: 670304736.0000\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1003561856.0000 - mae: 1003561856.0000\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2045579328.0000 - mae: 2045579328.0000\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2200256440.8889 - mae: 2200256440.8889\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2323909304.8889 - mae: 2323909304.8889\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1867346275.5556 - mae: 1867346275.5556\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1811458872.8889 - mae: 1811458872.8889\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1064687256.8889 - mae: 1064687256.8889\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 5262811562.6667 - mae: 5262811562.6667\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 8736756849.7778 - mae: 8736756849.7778\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7024788366.2222 - mae: 7024788366.2222\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11418696362.6667 - mae: 11418696362.6667\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 6806788437.3333 - mae: 6806788437.3333\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3096312120.8889 - mae: 3096312120.8889\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2187580181.3333 - mae: 2187580181.3333\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 6153885838.2222 - mae: 6153885838.2222\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8642710926.2222 - mae: 8642710926.2222\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 15038637624.8889 - mae: 15038637624.8889\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 16776805376.0000 - mae: 16776805376.0000\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16504856234.6667 - mae: 16504856234.6667\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8121368519.1111 - mae: 8121368519.1111\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7835420387.5556 - mae: 7835420387.5556\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8404243171.5556 - mae: 8404243171.5556\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 20559758535.1111 - mae: 20559758535.1111\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 16869411043.5556 - mae: 16869411043.5556\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 20605656177.7778 - mae: 20605656177.7778\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 27081435363.5556 - mae: 27081435363.5556\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 48968715377.7778 - mae: 48968715377.7778\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 55487940835.5556 - mae: 55487940835.5556\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 55239920298.6667 - mae: 55239920298.6667\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 30039256860.4444 - mae: 30039256860.4444\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 49573284067.5556 - mae: 49573284067.5556\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 91949515207.1111 - mae: 91949515207.1111\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 87427546680.8889 - mae: 87427546680.8889\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 49149559921.7778 - mae: 49149559921.7778\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 22171464476.4444 - mae: 22171464476.4444\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 63947046456.8889 - mae: 63947046456.8889\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 86803346773.3333 - mae: 86803346773.3333\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 82748753237.3333 - mae: 82748753237.3333\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 24980931015.1111 - mae: 24980931015.1111\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 44553061489.7778 - mae: 44553061489.7778\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 113759449543.1111 - mae: 113759449543.1111\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 123172430449.7778 - mae: 123172430449.7778\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 175817541404.4445 - mae: 175817541404.4445\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 177362709162.6667 - mae: 177362709162.6667\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 43829878897.7778 - mae: 43829878897.7778\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 130270704071.1111 - mae: 130270704071.1111\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 172100868323.5555 - mae: 172100868323.5555\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 309767527537.7778 - mae: 309767527537.7778\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 280761082766.2222 - mae: 280761082766.2222\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 124549366670.2222 - mae: 124549368490.6667\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 100816397198.2222 - mae: 100816397198.2222\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 124343853966.2222 - mae: 124343853966.2222\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 280124532053.3333 - mae: 280124532053.3333\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 489934043363.5555 - mae: 489934043363.5555\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 281194017223.1111 - mae: 281194017223.1111\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 769097094485.3334 - mae: 769097094485.3334\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 702201138744.8889 - mae: 702201138744.8889\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 826030788152.8889 - mae: 826030788152.8889\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 445611442176.0000 - mae: 445611442176.0000\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 631791149966.2222 - mae: 631791149966.2222\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 645314596408.8889 - mae: 645314596408.8889\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 708181955925.3334 - mae: 708181955925.3334\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 792959199914.6666 - mae: 792959199914.6666\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 889940931015.1111 - mae: 889940931015.1111\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 990812811719.1111 - mae: 990812811719.1111\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1108117189063.1111 - mae: 1108117189063.1111\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1254235919701.3333 - mae: 1254235919701.3333\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1412720951296.0000 - mae: 1412720951296.0000\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1578115028309.3333 - mae: 1578115028309.3333\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1763471505635.5557 - mae: 1763471505635.5557\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1989079888327.1111 - mae: 1989079888327.1111\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2251511991864.8887 - mae: 2251511991864.8887\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2538541023232.0000 - mae: 2538541023232.0000\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2822497479338.6665 - mae: 2822497479338.6665\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 3149753257528.8887 - mae: 3149753257528.8887\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3513954686293.3335 - mae: 3513954686293.3335\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3954410760874.6665 - mae: 3954410760874.6665\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 4467337636522.6670 - mae: 4467337636522.6670\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 5012679426048.0000 - mae: 5012679426048.0000\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 5654009814129.7773 - mae: 5654009814129.7773\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 6390187032576.0000 - mae: 6390187032576.0000\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7254761857934.2227 - mae: 7254761857934.2227\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8094462159530.6670 - mae: 8094462159530.6670\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9106708030350.2227 - mae: 9106708030350.2227\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10254046782350.2227 - mae: 10254046782350.2227\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11536599234787.5547 - mae: 11536599234787.5547\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 12946858049536.0000 - mae: 12946858049536.0000\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 14427995883292.4453 - mae: 14427995883292.4453\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16268254452849.7773 - mae: 16268254452849.7773\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 18276498509368.8906 - mae: 18276498509368.8906\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 20472162709959.1094 - mae: 20472162709959.1094\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 22858846816028.4453 - mae: 22858846816028.4453\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 25895787386197.3320 - mae: 25895787386197.3320\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 28938645420259.5547 - mae: 28938645420259.5547\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 32785379564657.7773 - mae: 32785379564657.7773\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 37769200708266.6641 - mae: 37769200708266.6641\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 42389420667335.1094 - mae: 42389420667335.1094\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 47617358692352.0000 - mae: 47617358692352.0000\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 53238553262307.5547 - mae: 53238553262307.5547\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 58565098908330.6641 - mae: 58565098908330.6641\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 65967703399537.7812 - mae: 65967703399537.7812\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 74915573370424.8906 - mae: 74915573370424.8906\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 83909785274140.4375 - mae: 83909785274140.4375\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 94933210307697.7812 - mae: 94933210307697.7812\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 105112733919914.6719 - mae: 105112733919914.6719\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 118070758371783.1094 - mae: 118070758371783.1094\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 131465052888177.7812 - mae: 131465052888177.7812\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 145993578548792.8750 - mae: 145993578548792.8750\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 164944805771491.5625 - mae: 164944805771491.5625\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 186797862216590.2188 - mae: 186797862216590.2188\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 206704944290929.7812 - mae: 206704944290929.7812\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 230463348146176.0000 - mae: 230463348146176.0000\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 258291531776000.0000 - mae: 258291531776000.0000\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 286669931661084.4375 - mae: 286669931661084.4375\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 320162608593123.5625 - mae: 320162608593123.5625\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 359874963002709.3125 - mae: 359874963002709.3125\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 403676594176000.0000 - mae: 403676594176000.0000\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 450635352535495.1250 - mae: 450635352535495.1250\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 504026130138908.4375 - mae: 504026130138908.4375\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 564199248305265.7500 - mae: 564199248305265.7500\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 636774748170922.6250 - mae: 636774748170922.6250\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 721234284598613.3750 - mae: 721234284598613.3750\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 816634083264284.5000 - mae: 816634083264284.5000\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 916860232124188.5000 - mae: 916860232124188.5000\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1032739381837824.0000 - mae: 1032739381837824.0000\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1171456267037354.7500 - mae: 1171456267037354.7500\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1325332015611904.0000 - mae: 1325332015611904.0000\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1478912455358691.5000 - mae: 1478912455358691.5000\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1642869506266453.2500 - mae: 1642869506266453.2500\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1851239740240327.0000 - mae: 1851239740240327.0000\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 2077086673360213.2500 - mae: 2077086673360213.2500\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2326363875952412.5000 - mae: 2326363875952412.5000\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2643609338656995.5000 - mae: 2643609338656995.5000\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2959596226813042.0000 - mae: 2959596226813042.0000\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 3324754316492800.0000 - mae: 3324754316492800.0000\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 3744495833186304.0000 - mae: 3744495833186304.0000\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4237152950011676.5000 - mae: 4237152950011676.5000\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4805731875640661.0000 - mae: 4805731875640661.0000\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 5354249993293369.0000 - mae: 5354249993293369.0000\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 5976917649216853.0000 - mae: 5976917649216853.0000\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 6661147278529877.0000 - mae: 6661147278529877.0000\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7443722711072768.0000 - mae: 7443722711072768.0000\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8286316553480875.0000 - mae: 8286316553480875.0000\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9296467091696298.0000 - mae: 9296467091696298.0000\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 10353148709073352.0000 - mae: 10353148709073352.0000\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 11699285591006322.0000 - mae: 11699285591006322.0000\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 13228630984010410.0000 - mae: 13228630984010410.0000\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 14919484088603990.0000 - mae: 14919484088603990.0000\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 16821482319045518.0000 - mae: 16821482319045518.0000\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 18803191086142804.0000 - mae: 18803191086142804.0000\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 21063685225986276.0000 - mae: 21063685225986276.0000\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 23895161504617812.0000 - mae: 23895161504617812.0000\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 27031160747516816.0000 - mae: 27031160747516816.0000\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 29851845204989268.0000 - mae: 29851845204989268.0000\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 33743305572934544.0000 - mae: 33743305572934544.0000\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 37819114527158728.0000 - mae: 37819114527158728.0000\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 42060568439524920.0000 - mae: 42060568439524920.0000\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 47419905463666464.0000 - mae: 47419905463666464.0000\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 53205083245801928.0000 - mae: 53205083245801928.0000\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 60361054720593464.0000 - mae: 60361054720593464.0000\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 68058431638412400.0000 - mae: 68058431638412400.0000\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 76924770759620832.0000 - mae: 76924770759620832.0000\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 87366320155845520.0000 - mae: 87366320155845520.0000\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 98617152582567712.0000 - mae: 98617152582567712.0000\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 108108360291829536.0000 - mae: 108108360291829536.0000\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 119365331181254880.0000 - mae: 119365331181254880.0000\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 133110453934664368.0000 - mae: 133110453934664368.0000\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 150288474373852736.0000 - mae: 150288474373852736.0000\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 168382904349491200.0000 - mae: 168382904349491200.0000\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 187400462144867904.0000 - mae: 187400462144867904.0000\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 210125563604733504.0000 - mae: 210125563604733504.0000\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 232135684722145504.0000 - mae: 232135684722145504.0000\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 261494512062882688.0000 - mae: 261494512062882688.0000\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 294090066844246912.0000 - mae: 294090066844246912.0000\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 328306567098488128.0000 - mae: 328306567098488128.0000\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 368308766257563392.0000 - mae: 368308766257563392.0000\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 416593643774905920.0000 - mae: 416593643774905920.0000\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 464318094870722816.0000 - mae: 464318094870722816.0000\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 527108306261741120.0000 - mae: 527108306261741120.0000\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 591989265737216512.0000 - mae: 591989265737216512.0000\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 664717787115261440.0000 - mae: 664717787115261440.0000\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 742951727376775424.0000 - mae: 742951727376775424.0000\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 827596591613462272.0000 - mae: 827596591613462272.0000\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 929241531976515584.0000 - mae: 929241547247510400.0000\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1058180428296588800.0000 - mae: 1058180428296588800.0000\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1207765030067852544.0000 - mae: 1207765030067852544.0000\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1348004874879150848.0000 - mae: 1348004874879150848.0000\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1517042402872903424.0000 - mae: 1517042402872903424.0000\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1699319364170634496.0000 - mae: 1699319364170634496.0000\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1879907613047055360.0000 - mae: 1879907613047055360.0000\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2090151141269103616.0000 - mae: 2090151141269103616.0000\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2364555204514516480.0000 - mae: 2364555204514516480.0000\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2635335033098862592.0000 - mae: 2635335033098862592.0000\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2956505006183343104.0000 - mae: 2956505006183343104.0000\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 3351201826260356608.0000 - mae: 3351201826260356608.0000\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3754016340685240320.0000 - mae: 3754016340685240320.0000\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 4155265455972067840.0000 - mae: 4155265455972067840.0000\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 4672654854447256576.0000 - mae: 4672654854447256576.0000\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 5234054068885549056.0000 - mae: 5234054068885549056.0000\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 5846947077891351552.0000 - mae: 5846947077891351552.0000\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 6579019756186573824.0000 - mae: 6579019756186573824.0000\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7435947477373899776.0000 - mae: 7435947477373899776.0000\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8344788212478815232.0000 - mae: 8344788212478815232.0000\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9370300447598256128.0000 - mae: 9370300447598256128.0000\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10486241405704339456.0000 - mae: 10486241405704339456.0000\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11675931922991560704.0000 - mae: 11675931922991560704.0000\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 13361337257661591552.0000 - mae: 13361337257661591552.0000\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 15072576228866013184.0000 - mae: 15072576228866013184.0000\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16666116878363525120.0000 - mae: 16666116878363525120.0000\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 18557941838337130496.0000 - mae: 18557941838337130496.0000\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 20809746783076642816.0000 - mae: 20809746783076642816.0000\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 23508921507597488128.0000 - mae: 23508921507597488128.0000\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 26337944645984002048.0000 - mae: 26337944645984002048.0000\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 29531502801474375680.0000 - mae: 29531502801474375680.0000\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 32884956824594284544.0000 - mae: 32884956824594284544.0000\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 36740471557540691968.0000 - mae: 36740471557540691968.0000\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 41202828992425140224.0000 - mae: 41202828992425140224.0000\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 46835650517769650176.0000 - mae: 46835650517769650176.0000\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 52531069439106703360.0000 - mae: 52531069439106703360.0000\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 59243909472746323968.0000 - mae: 59243909472746323968.0000\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 66888697028104388608.0000 - mae: 66888697028104388608.0000\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 74332439126659530752.0000 - mae: 74332439126659530752.0000\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 82515011013302370304.0000 - mae: 82515011013302370304.0000\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 92314821323556192256.0000 - mae: 92314821323556192256.0000\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 102450907247392669696.0000 - mae: 102450907247392669696.0000\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 113075587795646414848.0000 - mae: 113075587795646414848.0000\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 127738446653920411648.0000 - mae: 127738446653920411648.0000\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 143828696394091544576.0000 - mae: 143828696394091544576.0000\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 160870335953591205888.0000 - mae: 160870335953591205888.0000\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 180675713804730662912.0000 - mae: 180675713804730662912.0000\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 200177609831761543168.0000 - mae: 200177609831761543168.0000\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 224284792230874316800.0000 - mae: 224284792230874316800.0000\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 252892308952159027200.0000 - mae: 252892308952159027200.0000\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 283066266171179630592.0000 - mae: 283066266171179630592.0000\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 314858159148519129088.0000 - mae: 314858159148519129088.0000\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 356175846546284544000.0000 - mae: 356175846546284544000.0000\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 401763685262611120128.0000 - mae: 401763685262611120128.0000\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 452297145850203865088.0000 - mae: 452297145850203865088.0000\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 508950194954897063936.0000 - mae: 508950194954897063936.0000\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 576806321477955944448.0000 - mae: 576806321477955944448.0000\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 648605501940390166528.0000 - mae: 648605501940390166528.0000\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 726913036729945686016.0000 - mae: 726913036729945686016.0000\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 820345105536841678848.0000 - mae: 820345105536841678848.0000\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 915411418058519609344.0000 - mae: 915411418058519609344.0000\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1029063781311130894336.0000 - mae: 1029063781311130894336.0000\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 1144351467265935015936.0000 - mae: 1144351467265935015936.0000\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 1282780415143522598912.0000 - mae: 1282780415143522598912.0000\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 1443670542306413641728.0000 - mae: 1443670542306413641728.0000\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1621492820149582430208.0000 - mae: 1621492820149582430208.0000\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 1832656504852820787200.0000 - mae: 1832656504852820787200.0000\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2064801005932598788096.0000 - mae: 2064801005932598788096.0000\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 2309139159378469322752.0000 - mae: 2309139159378469322752.0000\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 2607871445098749231104.0000 - mae: 2607871445098749231104.0000\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 2955527318733573324800.0000 - mae: 2955527318733573324800.0000\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 3337822065952364167168.0000 - mae: 3337822065952364167168.0000\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 3716233678217446686720.0000 - mae: 3716233678217446686720.0000\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 4116888850517089320960.0000 - mae: 4116888850517089320960.0000\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 4605442309218994487296.0000 - mae: 4605442309218994487296.0000\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 5173046076080248586240.0000 - mae: 5173046076080248586240.0000\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 5844091365207711940608.0000 - mae: 5844091365207711940608.0000\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 6512229330575729623040.0000 - mae: 6512229330575729623040.0000\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 7347200266839923884032.0000 - mae: 7347200266839923884032.0000\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8217757771659673075712.0000 - mae: 8217757771659673075712.0000\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9186429071661450919936.0000 - mae: 9186429071661450919936.0000\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 10410568686825684074496.0000 - mae: 10410568686825684074496.0000\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 11748362580836122361856.0000 - mae: 11748362580836122361856.0000\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 13077292640179956219904.0000 - mae: 13077292640179956219904.0000\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14635546743149432930304.0000 - mae: 14635546743149432930304.0000\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 16364208549219312599040.0000 - mae: 16364208549219312599040.0000\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 18294201775030957768704.0000 - mae: 18294201775030957768704.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVx1JtwPP3-d"
      },
      "source": [
        "forcast=[]\r\n",
        "for time in range(len(series) - window_size):\r\n",
        "  forcast.append(rnn_model.predict(series[time:time + window_size][np.newaxis]))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVgv_LpQRnbB"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_wHAH3lR7xf"
      },
      "source": [
        "forcast = forcast[split_time - window_size : ]\r\n",
        "result = np.array(forcast)[:,0,0]"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIzR-gQnSj45"
      },
      "source": [
        "\r\n",
        "def plot_series(time, series, format=\"-\", start=0, end=None):\r\n",
        "    plt.plot(time[start:end], series[start:end], format)\r\n",
        "    plt.xlabel(\"Time\")\r\n",
        "    plt.ylabel(\"Value\")\r\n",
        "    plt.grid(True)\r\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "cnk8Q-uZSTc_",
        "outputId": "9946e8ed-fff4-4ffa-840b-72b137bf53e3"
      },
      "source": [
        "plt.figure(figsize=(10,6))\r\n",
        "plot_series(time_valid,x_valid)\r\n",
        "plot_series(time_valid,result)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6gg40F3St_x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}